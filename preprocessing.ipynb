{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Karanraj.K\n",
        "\n",
        "Htno: 2203A51241"
      ],
      "metadata": {
        "id": "xByK_jNdLgSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lowercase**"
      ],
      "metadata": {
        "id": "55CE-IfcFWMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_case(text):\n",
        "  return text.lower()\n",
        "text = \"Hi,This is assignment-1 of Information retrievel system\"\n",
        "print(lower_case(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvzcQB4oDgFC",
        "outputId": "921904d5-df10-4bc9-b152-52636b1c211e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi,this is assignment-1 of information retrievel system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove punctuations**"
      ],
      "metadata": {
        "id": "8kV7PxJCE3_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "  return ' '.join(text.translate(str.maketrans('', '', PUNCT_TO_REMOVE)).split())\n",
        "text = \"I'm having a lot of punctuations!!.@@@@@ All special characters will be removed *&&& ;)\"\n",
        "print(remove_punctuation(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eYX_F-qD1vO",
        "outputId": "d620efa8-d8a5-4786-f128-82cb18663e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Im having a lot of punctuations All special characters will be removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PUNCT_TO_REMOVE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uGBdX173EhlF",
        "outputId": "856460d2-29a8-435d-afee-94c32983e50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Stopwords**"
      ],
      "metadata": {
        "id": "G25l8IdxFwy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfjjF53RFvM0",
        "outputId": "ac79d31c-cc91-4a05-c08f-422c94e4f1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words('english')\n",
        "text = '''\n",
        "The rose is a beautiful flower\n",
        "'''\n",
        "print(\"\\nOriginal string:\")\n",
        "print(text)\n",
        "clean_word_list = [word for word in text.split() if word not in stoplist]\n",
        "print(\"\\nAfter removing stop words from the said text:\")\n",
        "print(clean_word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpy37BQ2E8Dh",
        "outputId": "136acc8e-4ce7-476f-e666-6449aaae7553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original string:\n",
            " \n",
            "The rose is a beautiful flower \n",
            "\n",
            "\n",
            "After removing stop words from the said text:\n",
            "['The', 'rose', 'beautiful', 'flower']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Removing URLS**"
      ],
      "metadata": {
        "id": "_Y-8rwFlGJvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_URL(sample):\n",
        "    \"\"\"Remove URLs from a sample string\"\"\"\n",
        "    return re.sub(r\"http\\S+\", \"\", sample)\n",
        "\n",
        "print(remove_URL('URL of whatsapp https://web.whatsapp.com/'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDCJdIGPGGhn",
        "outputId": "cf7dfcee-c4b0-48e7-b7e9-affc4f55ca8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL of whatsapp \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Removing Emojis**"
      ],
      "metadata": {
        "id": "D6Lkld_pGb5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "print(remove_emoji(\" ðŸ˜˜ Removing emojis for text preprocessing ðŸ˜˜ðŸ˜˜\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QPWqGDGPPK",
        "outputId": "097393c7-9811-4a1c-b44f-0f03e7c4b22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Removing emojis for text preprocessing \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eliminating stopwords**"
      ],
      "metadata": {
        "id": "eZuPKoGZIrAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "-RbrPJbPH-RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_tokenization(text):\n",
        "  return text.split()\n",
        "text = \"Hi,This is assignment-1 of Information retrievel system\"\n",
        "print(word_tokenization(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7NwEzsbGy5d",
        "outputId": "7994d021-ca39-42b0-f27a-88e896aa9b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi,This', 'is', 'assignment-1', 'of', 'Information', 'retrievel', 'system']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_tokenization(text):\n",
        "  return text.split('.')\n",
        "text = \"I am karan. This is my IRS lab assignment\"\n",
        "print(sentence_tokenization(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7zBzZvDIOZa",
        "outputId": "0da18782-7481-4949-d86e-1cca99ed1435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I am karan', ' This is my IRS lab assignment', '']\n"
          ]
        }
      ]
    }
  ]
}